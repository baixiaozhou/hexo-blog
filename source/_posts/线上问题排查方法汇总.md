---
title: 线上故障排查方法和工具介绍
author: baixiaozhou
categories:
  - 问题排查
tags:
  - Linux
  - Java
  - Golang
  - commands
description: 线上故障问题的排查方法和工具介绍，包括 CPU、内存、负载、磁盘、IO、网络等
date: 2024-08-15 11:12:21
references:
  - '[Examining Load Average](https://www.linuxjournal.com/article/9001)'
  - '[What-is-CPU-Load-Average](https://community.tenable.com/s/article/What-is-CPU-Load-Average)'
cover: /images/server.jpg
banner: /images/server.jpg
---

<!-- more -->

- [写在前面](#写在前面)
- [CPU使用率飙升](#cpu使用率飙升)
  - [如何让CPU使用率飙升](#如何让cpu使用率飙升)
  - [如何判断和发现CPU使用率飙升](#如何判断和发现cpu使用率飙升)
  - [如何确定CPU飙升的根源](#如何确定cpu飙升的根源)
    - [perf命令](#perf命令)
    - [jstack](#jstack)
    - [火焰图](#火焰图)
- [负载飙升](#负载飙升)
  - [负载的定义以及如何查看负载](#负载的定义以及如何查看负载)
  - [CPU的使用情况 VS loadavg](#cpu的使用情况-vs-loadavg)


## 写在前面

在很多文章中，每当提到去解决线上问题的时候，大部分的处理方式就是登录环境，哐哐各种敲命令。操作本身没什么问题，但是对于很多人而言，我觉得这种做法其实是本末倒置的，过于在乎去快速抓住重点问题，而忽略了从全局去看问题。那么如果最开始不去操作各种命令，那应该干什么呢？

***看监控！！！！***

首先不要觉得这个是废话，对于很多场景来说，业务规模是不断变化的，有的时候并发超过了极限的性能，那么这种情况下都没有必要去后台进行各种查询。举个简单的例子，假如说某套业务系统，本身只能支持 500 并发，现在实际上的量到了 2000，导致线上各种内存、CPU、负载的告警，这种情况下还有必要去后台敲`top`、`free`吗？答案当然是否定的，这种情况下，就需要考虑对业务系统进行快速的扩容等。

看监控的意义在于尽可能的找到更多的性能瓶颈或者异常的点，从全局出发，对系统当前存在的问题和异常点有全面的了解。

监控系统多种多样，从较早的 zabbix 到现在比较流行的prometheus+grafana（举两个常用的例子），对于系统业务都有比较完善的监控，可以帮助我们更加具体的了解到系统运行全貌。如果你对这些都不喜欢，那么你自己写一个监控系统也没什么问题。

当我们看完监控之后（假设你真的看了），接下来进入实际操作环节，我会从这些指标的详细含义出发，然后尽可能地将各种处理方式分享给大家。

## CPU使用率飙升

### 如何让CPU使用率飙升

这个问题其实很简单，只要有计算任务一直存在，让 CPU 一直处于繁忙之中，那么 CPU 必然飙升。我们可以通过一系列的工具去模拟这个情况。

[github SysStress](https://github.com/baixiaozhou/SysStress) 这是我自己用 golang 写的压测工具(还在开发中，可以点个 star 让我更有动力😂)

使用方法:
```
./sysstress cpu --cpu-number 10 --duration 10m
```
这个就是模拟占用 10 核心的 CPU 并持续 10min，当然大家也可以用其他的压测工具，比如`stress-ng`

### 如何判断和发现CPU使用率飙升

首先我们先看一下，跟 CPU 使用率相关的有哪些指标。我们通过 `top` 命令就可以看到具体的信息

![top](../images/top.png)
这些输出中有一行是 `%Cpu(s)`, 这行展示了 CPU 的整体使用情况，是一个百分比的形式，我们详细阐述下这几个字段的含义
```
us, user    : time running un-niced user processes   未降低优先级的用户进程所占用的时间
sy, system  : time running kernel processes          内核进程所占用的时间
ni, nice    : time running niced user processes      降低优先级的用户进程所占用的时间
id, idle    : time spent in the kernel idle handler  空闲的时间
wa, IO-wait : time waiting for I/O completion        等待 I/O 操作完成所花费的时间
hi : time spent servicing hardware interrupts        处理硬件中断所花费的时间
si : time spent servicing software interrupts        处理软件中断所花费的时间
st : time stolen from this vm by the hypervisor      被虚拟机管理程序从此虚拟机中窃取的时间
```
在这些指标中，一般关注的比较多的就是 us、sy、id、wa（其他几个指标很高的情况我个人目前基本上没有遇到过）

上述指标反映了系统整体的 CPU 情况。而程序在操作系统中实际上是以一个个的进程存在的，那我们如何确定到占用 CPU 高的进程呢？让我们的目光从 top 的头部信息往下移动，下面就展示了详细的进程信息
![top-process](../images/top-process.png)

这些程序默认是按照 CPU 的使用率从高到底进行排序的，当然你也可以通过在`top`的时候输入`P`进行排序，这样我们就可以看到系统中消耗 CPU 资源的详细进程信息

上面是我通过 `./sysstress cpu --cpu-number 10 --duration 10m` 压测程序跑出来的，可以看到这里的 sysstress 程序占用了 1002 的 %CPU，也就是说基本上是 10 个核心，那我们跑一个更高的，将`--cpu-number`加到 60 看看发生了什么
![stress-cpu](../images/stress-cpu.png)

我们可以看到这次%CPU打到了 6000，那很多人就好奇我日常的程序跑到多高算高呢？

这里我们需要明确一点，现在的服务器绝大部分都是多核心 CPU（1C2G这种自己用来玩的忽略），CPU 的核心数决定了我们程序在同一时间能够执行多少个线程，也就是说，这个高不高是相对于机器配置而言的。如果你的机器只有 16C，那么单个进程占用的 %CPU 到 1000，那么其实已经算是比较高了。如果是 256C 的CPU（土豪级配置），那么单个进程占用的 %CPU 到 6000，对于系统的稳定性影响就没有那么大了。

上述我们说的情况是进程占用 CPU 对整个系统的影响，那么进程占用的 CPU 对系统的影响不大就代表这个程序一定没有问题吗？答案显然是未必的。

我们还是要回归到业务本身，如果进程的 CPU 占用在业务变动不大的情况下，发生了异常波动，或者正常情况下业务不会消耗这么高的 CPU，那么我们就需要继续排查了。

### 如何确定CPU飙升的根源
这个问题的 核心是 CPU 上在运行什么东西。 多核心CPU 下，每个核心都可以执行不同的程序，我们如何确定一个进程中那些方法在消耗 CPU 呢？从而引申下面详细的问题:
 1. 程序的调用栈是什么样的？
 2. 调用栈信息中哪些是需要关注的，那些是可以忽略的？
 3. 热点函数是什么？

老话说得好，"工欲善其事，必先利其器", 我们需要这些东西，就必须了解到什么样的工具可以拿到上面我提到的一些信息。接下来我将通过常用的后端语言：`golang` 和 `java` 为例构造一些高 CPU 的程序来进行展示。

#### perf命令
**perf是一款Linux性能分析工具。Linux性能计数器是一个新的基于内核的子系统，它提供一个性能分析框架，比如硬件（CPU、PMU(Performance Monitoring Unit)）功能和软件(软件计数器、tracepoint)功能。**

安装:
```
yum install perf   #Centos
```
安装完成后，我们可以首先看下 `perf`的用法，这里不展开具体用法，只列出我平常使用的几个命令:
```
top        System profiling tool.               #对系统性能进行实时分析。
record     Run a command and record its profile into perf.data     #收集采样信息
report     Read perf.data (created by perf record) and display the profile  #分析采样信息，和record配合使用
```
record 和 report 的使用更多在于 dump 当前环境的信息用于后续分析，如果在自己环境上测试，可以用 top 进行一些简单的实时分析（类似于 top 命令）。

还是用之前的压测工具，我们模拟一个 10 核心的 10min 的压测场景
```
nohup ./sysstress cpu --cpu-number 10 --duration 10m > /dev/null 2>&1 &
```
执行这个语句，让压测程序在后台执行，然后我们通过`perf top`查看具体的情况（可以通过-p 指定 pid）

![perf top](../images/perftop.png)

从截图的信息中我们可以看到占用资源最多的一些方法，包括 sysstress 进程的各种方法(从图片中基本上就可以确定高消耗的方法在哪里)以及底层的 `__vdso_clock_gettime`, 那再结合压测工具的代码分析下:

``` golang
func burnCpu(wg *sync.WaitGroup, start time.Time, durSec int64) {
	defer wg.Done()
	for {
		_ = 1 * 1
		now := time.Now()
		if now.Sub(start) > time.Duration(durSec)*time.Second {
			break
		}
	}
}
```
这是方法的核心，其实就是做无意义的计算，外加时间的判断，超过 duration 就结束。这样和上面的 perf top 信息就能对应起来。

然后我们用 java 写一个同样的程序，再看看 `perf top`的情况:
![perf top](../images/javaperftop.png)
从这一大段显示来看，是不是看的一脸懵逼，很难发现到底是什么程序在占用CPU 资源。大家可以看一下源程序:
``` java
import java.time.LocalDateTime;

public class Main {
    public static void main(String[] args) {
        int n = 10;

        for (int i = 0; i < 10; i++) {
            new Thread(new Runnable() {
                public void run() {
                    while (true) {
                        Math.sin(Math.random());
                        LocalDateTime currentTime = LocalDateTime.now();
                    }
                }
            }).start();
        }
    }
}
```
这里的程序也是非常简单，启动 10 个线程，做一个无意义的数学运算，然后获取当前时间。从这段代码中是不是很难和上面`perf top`的显示关联起来？ 原因也非常简单， 像Java 这种通过 JVM 来运行的应用程序，运行堆栈用的都是 JVM 内置的函数和堆栈管理。所以，从系统层面只能看到 JVM 的函数堆栈，而不能直接得到 Java 应用程序的堆栈。那我们好能通过 perf 去看到 java 相关的堆栈吗？答案是可以的。

可以借助 [perf-map-agent](https://github.com/jvm-profiling-tools/perf-map-agent) 这样的开源工具，去生成和`perf` 工具一起使用的方法映射，但是需要做额外的一些配置。这里的方法大家可以自己探究，为什么不详细的讲这个呢，原因也简单，排查问题的工具多种多样，没必要在一棵树上吊死。

#### jstack

既然 perf top 去查看 JAVA 的调用栈不太方便，我们就直接上 java 提供的 jstack 工具去分析。
- jstack -l pid > xxx.txt 需要注意的是，linux系统中往往会用不同的用户去执行不同的程序，此时可能需要通过sudu -u xxx jstack的形式
- kill -3， jstack 用不了的情况下可以使用 kill -3 pid 的形式，堆栈会输出在系统日志中。

具体的操作步骤:
1. `top -Hp $pid` 找到占用 CPU 的具体线程
2. `jstack -l $pid > /tmp/$pid.jstack` 或者 `kill -3 $pid`将 java 进程的堆栈情况输出的日志中，然后根据 `top -Hp` 看到的线程信息在输出的堆栈日志中进行查找（`top -Hp` 输出的是 10 进制的 id，`jstack` 输出的是 16 进制的，在查找时注意进制转换）

我们看下上面 java 程序的堆栈的信息:
``` Lua
2024-08-16 15:15:40
Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.221-b11 mixed mode):

"Attach Listener" #35 daemon prio=9 os_prio=0 tid=0x00007f52b4001000 nid=0x71f4 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"DestroyJavaVM" #34 prio=5 os_prio=0 tid=0x00007f53e0009800 nid=0x1693 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"Thread-1" #25 prio=5 os_prio=0 tid=0x00007f53e015a800 nid=0x16d9 runnable [0x00007f52f64e3000]
   java.lang.Thread.State: RUNNABLE
	at sun.misc.Unsafe.getObjectVolatile(Native Method)
	at java.util.concurrent.ConcurrentHashMap.tabAt(ConcurrentHashMap.java:755)
	at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:938)
	at java.time.zone.ZoneRulesProvider.getProvider(ZoneRulesProvider.java:267)
	at java.time.zone.ZoneRulesProvider.getRules(ZoneRulesProvider.java:227)
	at java.time.ZoneRegion.ofId(ZoneRegion.java:120)
	at java.time.ZoneId.of(ZoneId.java:411)
	at java.time.ZoneId.of(ZoneId.java:359)
	at java.time.ZoneId.of(ZoneId.java:315)
	at java.util.TimeZone.toZoneId(TimeZone.java:556)
	at java.time.ZoneId.systemDefault(ZoneId.java:274)
	at java.time.Clock.systemDefaultZone(Clock.java:178)
	at java.time.LocalDateTime.now(LocalDateTime.java:180)
	at Main$1.run(Main.java:12)
	at java.lang.Thread.run(Thread.java:748)

   Locked ownable synchronizers:
	- None

"Thread-0" #24 prio=5 os_prio=0 tid=0x00007f53e0159000 nid=0x16d8 runnable [0x00007f52f65e4000]
   java.lang.Thread.State: RUNNABLE
	at sun.misc.Unsafe.getObjectVolatile(Native Method)
	at java.util.concurrent.ConcurrentHashMap.tabAt(ConcurrentHashMap.java:755)
	at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:938)
	at java.time.zone.ZoneRulesProvider.getProvider(ZoneRulesProvider.java:267)
	at java.time.zone.ZoneRulesProvider.getRules(ZoneRulesProvider.java:227)
	at java.time.ZoneRegion.ofId(ZoneRegion.java:120)
	at java.time.ZoneId.of(ZoneId.java:411)
	at java.time.ZoneId.of(ZoneId.java:359)
	at java.time.ZoneId.of(ZoneId.java:315)
	at java.util.TimeZone.toZoneId(TimeZone.java:556)
	at java.time.ZoneId.systemDefault(ZoneId.java:274)
	at java.time.Clock.systemDefaultZone(Clock.java:178)
	at java.time.LocalDateTime.now(LocalDateTime.java:180)
	at Main$1.run(Main.java:12)
	at java.lang.Thread.run(Thread.java:748)

   Locked ownable synchronizers:
	- None
 --- 10 个 thread

"Service Thread" #23 daemon prio=9 os_prio=0 tid=0x00007f53e0143800 nid=0x16d6 runnable [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"C2 CompilerThread1" #6 daemon prio=9 os_prio=0 tid=0x00007f53e010e000 nid=0x16c5 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None
 --- 一大堆 C2 CompilerThread

"C2 CompilerThread0" #5 daemon prio=9 os_prio=0 tid=0x00007f53e010b000 nid=0x16c4 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"Signal Dispatcher" #4 daemon prio=9 os_prio=0 tid=0x00007f53e0109800 nid=0x16c3 runnable [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"Finalizer" #3 daemon prio=8 os_prio=0 tid=0x00007f53e00d8800 nid=0x16c2 in Object.wait() [0x00007f52f7bfa000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on <0x000000008021a5e8> (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
	- locked <0x000000008021a5e8> (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
	at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:216)

   Locked ownable synchronizers:
	- None

"Reference Handler" #2 daemon prio=10 os_prio=0 tid=0x00007f53e00d3800 nid=0x16c1 in Object.wait() [0x00007f52f7cfb000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on <0x0000000080218d38> (a java.lang.ref.Reference$Lock)
	at java.lang.Object.wait(Object.java:502)
	at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
	- locked <0x0000000080218d38> (a java.lang.ref.Reference$Lock)
	at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)

   Locked ownable synchronizers:
	- None

"VM Thread" os_prio=0 tid=0x00007f53e00ca000 nid=0x16c0 runnable

"GC task thread#0 (ParallelGC)" os_prio=0 tid=0x00007f53e001f000 nid=0x1694 runnable

--- 一大堆 GC task thread

"VM Periodic Task Thread" os_prio=0 tid=0x00007f53e0146000 nid=0x16d7 waiting on condition

JNI global references: 202
```
我们通过 top -Hp 的信息就可以快速定位到 Thread-[0-9] 这几个线程，而每个线程的调用栈都是 `java.time.LocalDateTime.now`, 也说明了这个方法在不停消耗 CPU。（但是 jstack 只能捕获短时间或者瞬时的堆栈信息，没法处理长时间的，所以我们在获取时可以多打印几次或者使用其他方法）

至于 jstack 的详细用法，请参考我的另一篇博客：[java问题定位](https://baixiaozhou.github.io/2024/08/13/JAVA%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/)

除此之外，还有非常多的分析工具，pstack\gstack\strace\gdb等等，大家可以自行探索使用

#### 火焰图

上面我们介绍了很多操作的命令和方法，那么有没有一种比较直观的方式能够直接看到各种方法执行的耗时比重等情况呢？火焰图就是为了解决这种情况而生的。

火焰图的分类有很多，常用的包括:
1. CPU 火焰图 (CPU Flame Graph)
	-	描述：展示 CPU 在不同方法上的消耗情况，显示每个方法调用所占用的 CPU 时间。
	-	用途：用于分析 CPU 性能瓶颈，识别哪些方法消耗了最多的 CPU 资源。
	-	应用：Java、C++ 等多种编程语言的性能分析。
2. 内存火焰图 (Memory Flame Graph)
	- 描述：展示内存分配情况，显示每个方法调用分配的内存量。
    - 用途：用于检测内存泄漏、过度内存分配问题，帮助优化内存使用。
	- 应用：常用于分析内存密集型应用，如 Java 应用的堆内存分析。
3. I/O 火焰图 (I/O Flame Graph)
	-	描述：展示 I/O 操作的耗时情况，显示不同方法的 I/O 操作占用的时间。
	-	用途：用于分析应用程序的 I/O 性能，识别慢速或频繁的 I/O 操作。
	-	应用：数据库查询、文件系统操作、网络通信等场景的性能调优。

我们这里通过 [async-profiler](https://github.com/async-profiler/async-profiler) 对文章上面的java压测程序进行抓取(这个工具只能抓 java 的)

```
tar -xzf async-profiler-3.0-linux-x64.tar.gz
cd async-profiler-3.0-linux-x64/bin
./asprof -d 60 pid -f /tmp/javastress.html
```
我们用浏览器打开生成的 html 文件，可以看到如下的火焰图信息（可以在网页进行点击，查看更细节的方法）
![java 程序的火焰图](../images/javafire.png)

这样看起来就比 jstack这些信息更加直观一点。

## 负载飙升

### 负载的定义以及如何查看负载

我们先看下系统负载的官方描述:
```
System load averages is the average number of processes that are either in a runnable or uninterruptable state. A process in arunnable state is either using the CPU or waiting to use the CPU.  A process in uninterruptable state is waiting for some I/O access,eg waiting for disk.  The averages are taken over the three time intervals.  Load averages are not normalized for the number of CPUs ina  system,  so a load average of 1 means a single CPU system is loaded all the time while on a 4 CPU system it means it was idle 75% of the time.
```

系统负载平均值表示处于可运行或不可中断状态的进程的平均数量。处于可运行状态的进程要么正在使用 CPU，要么正在等待使用 CPU。处于不可中断状态的进程正在等待某些 I/O 访问，例如等待磁盘。这里的核心概念就是 loadavg 这个数值体现了某些特定状态进程的数量。

那引申出两个问题:
1. 进程的状态有哪些？
2. 可运行和不可中断状态的进程具体含义是什么

首先我们看下，进程的状态和具体含义:
- D    uninterruptible sleep (usually IO)
- R    running or runnable (on run queue)
- S    interruptible sleep (waiting for an event to complete)
- T    stopped by job control signal
- t    stopped by debugger during the tracing
- W    paging (not valid since the 2.6.xx kernel)
- X    dead (should never be seen) 
- Z    defunct ("zombie") process, terminated but not reaped by its parent

这里我们看到处于不可中断的状态的进程和正在运行的进程分别为 `D` 和 `R`,换个说法，也就是说造成负载升高的原因也就是这两个状态的进程引起的。

（插个题外话，按照官方的说法，X 状态的进程应该是不应该被看到的， 但是之前在腾讯云做ES的时候，偶然间碰到了一次，当时还截了个图用做留念😂，但是没有捕获到具体的信息）

负载的指标可以通过 `top` 以及 `uptime` 指令获取
```
23:35:00 up 1 day, 46 min,  1 user,  load average: 49.16, 18.35, 7.87
```
这里展示了 loadavg 的三个数值: 分别代表的含义是 1min、5min、15min 的系统平均负载

### CPU的使用情况 VS loadavg

既然说正在运行的进程会引起负载的变化，那么跑一些程序，让程序不停运行，那么自然而然就能构造出持续运行的进程了。
我这里找了三台机器(64C)，用我的压测工具先跑一些纯 CPU 的运算，然后观察下效果：

测试分为三组，测试前关闭不必要的服务和进程:
1. 10 并发 30min
   -  `nohup ./sysstress cpu --cpu-number 10 --duration 30m > /dev/null 2>&1`
2. 30 并发 30min
   - `nohup ./sysstress cpu --cpu-number 30 --duration 30m > /dev/null 2>&1`
3. 60 并发 30min
   - `nohup ./sysstress cpu --cpu-number 60 --duration 30m > /dev/null 2>&1`

效果如下:
![10并发负载](../images/load10.png)
![30并发负载](../images/load30.png)
![60并发负载](../images/load60.png)

从上述测试过程中，我们可以发现，在纯运算这种场景下，并发的量基本上和负载是对应的。也就是说随着 CPU的使用量 上涨，负载也会不断变高。
